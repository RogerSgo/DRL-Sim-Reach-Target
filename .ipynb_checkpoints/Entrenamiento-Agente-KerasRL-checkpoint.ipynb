{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c322dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import CoppeliaSim_Gym # carpeta del entorno\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef58887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Input, Conv2D, MaxPooling2D, Permute, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model # Graficar modelo CNN\n",
    "from keras.initializers import random_normal\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.core import Processor\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8048f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES\n",
    "INPUT_SHAPE = (256, 256)\n",
    "WINDOW_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3835a884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado al servidor API remoto\n"
     ]
    }
   ],
   "source": [
    "# PREPARACION DEL ENTORNO \n",
    "ENV_NAME = \"CoppeliaSim_Gym/GymCoppManR-v0\"\n",
    "env = gymnasium.make(ENV_NAME) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bc8df85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "observation, info = env.reset(is_dynamic=True) # Empezar episodio realizando una observacion\n",
    "#ent = (observation['c_image']/255).shape\n",
    "ent = observation.shape\n",
    "#print(ent)\n",
    "actions = env.action_space.shape[0] # mostrar espacio accion de 7 valores\n",
    "#width, higth, channel = observation['c_image'].shape[0], observation['c_image'].shape[1], observation['c_image'].shape[2]\n",
    "#shape_img = (width, higth, channel)\n",
    "#print(shape_img)\n",
    "#print(info['info'])\n",
    "#print(f'\\info: \\n{info}')\n",
    "print(actions)\n",
    "print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0d71911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#o = env.step(1)\n",
    "#print ('imagen:', observation)\n",
    "#print(observation)\n",
    "#print('Angulos de las articulaciones:',env.joint_angles())\n",
    "#te = [0.0, 1.1, 0.0, -1.0, 0.0, 2., 0.0] #posicion inicial del el extremo de path\n",
    "#print('CambioPosicion', env.set_posicion(te))\n",
    "#print('Distancia desde el punto al objetivo:', env.distance_to_goal())\n",
    "#env.set_posicion(te)\n",
    "#print('Verificar colision', env.A_colision())\n",
    "\n",
    "#print(\"The new observation is {}\".format(observation))\n",
    "#observation_next, reward, done, info = env.step(env.action_space.sample())\n",
    "#print(f'observation: \\n{observation} \\nreward: \\n{reward} \\ndone: \\n{done} \\ninfo: \\n{info}')\n",
    "#print(f'observation space: \\n{env.observation_space} \\naction space: \\n{env.action_space}')\n",
    "\n",
    "#img=env.render(mode=\"rgb_array\")\n",
    "#plt.imshow(img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "060ff7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESAR DATOS DE OBSERVACION, ACCION Y RECOMPENSA\n",
    "class CoppeliaProcessor(Processor):\n",
    "    def process_observation(observation):\n",
    "        assert observation.ndim == 3  # (altura, ancho, canal)\n",
    "        img = Image.fromarray(observation)\n",
    "        img = img.resize(INPUT_SHAPE).convert('L')  # resize and convert to grayscale\n",
    "        processed_observation = np.array(img)\n",
    "        assert processed_observation.shape == INPUT_SHAPE\n",
    "        return processed_observation.astype('uint8')  # saves storage in experience memory\n",
    "\n",
    "    def process_state_batch(batch):\n",
    "        # We could perform this processing step in `process_observation`. In this case, however,\n",
    "        # we would need to store a `float32` array instead, which is 4x more memory intensive than\n",
    "        # an `uint8` array. This matters if we store 1M observations.\n",
    "        processed_batch = batch.astype('float32')/255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0253a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo CNN.\n",
    "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
    "model = Sequential()\n",
    "model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "model.add(Conv2D(32, (8, 8), strides=(4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (4, 4), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(actions))\n",
    "model.add(Activation('linear'))\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8e9588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "pic_input = Input(shape=(ent)) # shape=(255,255,1)\n",
    "\n",
    "img_stack = Conv2D(16, (3, 3), name='capa1', padding='same', activation=activation)(pic_input)\n",
    "img_stack = MaxPooling2D(pool_size=(2,2))(img_stack)\n",
    "img_stack = Conv2D(32, (3, 3), activation=activation, padding='same', name='capa2')(img_stack)\n",
    "img_stack = MaxPooling2D(pool_size=(2, 2))(img_stack)\n",
    "img_stack = Conv2D(32, (3, 3), activation=activation, padding='same', name='capa3')(img_stack)\n",
    "img_stack = MaxPooling2D(pool_size=(2, 2))(img_stack)\n",
    "img_stack = Flatten()(img_stack)\n",
    "img_stack = Dropout(0.2)(img_stack)\n",
    "\n",
    "img_stack = Dense(128, name='rl_dense', kernel_initializer=random_normal(stddev=0.01))(img_stack)\n",
    "img_stack=Dropout(0.2)(img_stack)\n",
    "output = Dense(actions, name='rl_output', kernel_initializer=random_normal(stddev=0.01))(img_stack)\n",
    "\n",
    "opt = Adam()\n",
    "action_model = Model(inputs=[pic_input], outputs=output)\n",
    "\n",
    "action_model.compile(optimizer=opt, loss='mean_squared_error')\n",
    "#print(action_model.summary())\n",
    "#plot_model(model, to_file='img_file.png', show_shapes=True) # Graficar modelo, conda install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e8754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_callbacks(env): # registro\n",
    "    checkpoint_weights_filename = 'dqn_' + env + '_weights_{step}.h5f'\n",
    "    log_filename = 'dqn_{}_log.json'.format(env)\n",
    "    callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=5000)]\n",
    "    callbacks += [FileLogger(log_filename, interval=100)]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d5d6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros para el agente DQN\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=1., value_rest=.05, nb_steps=10000)\n",
    "processor = CoppeliaProcessor()\n",
    "memory = SequentialMemory(limit=50000, window_length=WINDOW_LENGTH)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4d15b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQNAgent(model=model, nb_actions=actions, policy=policy, memory=memory,\n",
    "               processor=processor, nb_steps_warmup=50000, gamma=.99, target_model_update=10000,\n",
    "               train_interval=4, delta_clip=1.)\n",
    "dqn.compile(Adam(learning_rate=.0001), metrics=['mae'])\n",
    "callbacks = build_callbacks('CoppeliaSim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7b4aa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50 steps ...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# , callbacks=callbacks\u001b[39;00m\n\u001b[0;32m      2\u001b[0m scores \u001b[38;5;241m=\u001b[39m dqn\u001b[38;5;241m.\u001b[39mtest(env, nb_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, visualize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, log_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(scores\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecompensa_episodio\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\rl\\core.py:133\u001b[0m, in \u001b[0;36mAgent.fit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    131\u001b[0m observation \u001b[38;5;241m=\u001b[39m deepcopy(env\u001b[38;5;241m.\u001b[39mreset())\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m observation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Perform random starts at beginning of episode and do not record them into the experience.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# This slightly changes the start position between games.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m, in \u001b[0;36mCoppeliaProcessor.process_observation\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_observation\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mobservation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# (height, width, channel)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(observation)\n\u001b[0;32m      5\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize(INPUT_SHAPE)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# resize and convert to grayscale\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=50, visualize=False, verbose=2, callbacks=callbacks) # , callbacks=callbacks\n",
    "scores = dqn.test(env, nb_episodes=100, visualize=True, log_interval=10000)\n",
    "print(np.mean(scores.history['recompensa_episodio']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af52e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = Input(shape=(255,255,1))\n",
    "model = tf.keras.models.Sequential()\n",
    "# Añadimos la primera capa\n",
    "model.add(Conv2D(128,(4,4), activation = 'relu', input_shape = (ent)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides=(2, 2)))\n",
    "# Añadimos la segunda capa\n",
    "model.add(Conv2D(64,(2,2), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# Hacemos un flatten para poder usar una red fully connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Flatten())\n",
    "# Añadimos una capa softmax para que podamos clasificar las imágenes\n",
    "model.add(Dense(actions, activation='softmax'))\n",
    "\n",
    "#print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34aa57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
